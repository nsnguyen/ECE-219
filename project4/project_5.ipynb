{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where we will only use what we need.\n",
    "\n",
    "filename = 'ECE219_tweet_data/tweets_#gohawks.txt'\n",
    "output_filename = 'Q1_2#gohawks.lol'\n",
    "\n",
    "with open(filename, 'r') as reader:\n",
    "    headers = ['citation_date','tweets','retweets','followers']\n",
    "    with open(output_filename, 'w') as writer:\n",
    "        csv_writer = csv.writer(writer, lineterminator='\\n')\n",
    "        csv_writer.writerow(headers)\n",
    "        for line in reader:\n",
    "            data = json.loads(line)\n",
    "            response = [datetime.datetime.fromtimestamp(data['citation_date']),\n",
    "                        1, # there is one tweet at a time..\n",
    "                        data['metrics']['citations']['total'], #retweets\n",
    "                        data['author']['followers'], #followers\n",
    "                         ]\n",
    "            csv_writer.writerow(response)\n",
    "            \n",
    "            \n",
    "            \n",
    "filename = 'ECE219_tweet_data/tweets_#gopatriots.txt'\n",
    "output_filename = 'Q1_2#gopatriots.lol'\n",
    "\n",
    "with open(filename, 'r') as reader:\n",
    "    headers = ['citation_date','tweets','retweets','followers']\n",
    "    with open(output_filename, 'w') as writer:\n",
    "        csv_writer = csv.writer(writer, lineterminator='\\n')\n",
    "        csv_writer.writerow(headers)\n",
    "        for line in reader:\n",
    "            data = json.loads(line)\n",
    "            response = [datetime.datetime.fromtimestamp(data['citation_date']),\n",
    "                        1, # there is one tweet at a time..\n",
    "                        data['metrics']['citations']['total'], #retweets\n",
    "                        data['author']['followers'], #followers\n",
    "                         ]\n",
    "            csv_writer.writerow(response)\n",
    "\n",
    "            \n",
    "filename = 'ECE219_tweet_data/tweets_#nfl.txt'\n",
    "output_filename = 'Q1_2#nfl.lol'\n",
    "\n",
    "with open(filename, 'r') as reader:\n",
    "    headers = ['citation_date','tweets','retweets','followers']\n",
    "    with open(output_filename, 'w') as writer:\n",
    "        csv_writer = csv.writer(writer, lineterminator='\\n')\n",
    "        csv_writer.writerow(headers)\n",
    "        for line in reader:\n",
    "            data = json.loads(line)\n",
    "            response = [datetime.datetime.fromtimestamp(data['citation_date']),\n",
    "                        1, # there is one tweet at a time..\n",
    "                        data['metrics']['citations']['total'], #retweets\n",
    "                        data['author']['followers'], #followers\n",
    "                         ]\n",
    "            csv_writer.writerow(response)\n",
    "\n",
    "            \n",
    "filename = 'ECE219_tweet_data/tweets_#patriots.txt'\n",
    "output_filename = 'Q1_2#patriots.lol'\n",
    "\n",
    "with open(filename, 'r') as reader:\n",
    "    headers = ['citation_date','tweets','retweets','followers']\n",
    "    with open(output_filename, 'w') as writer:\n",
    "        csv_writer = csv.writer(writer, lineterminator='\\n')\n",
    "        csv_writer.writerow(headers)\n",
    "        for line in reader:\n",
    "            data = json.loads(line)\n",
    "            response = [datetime.datetime.fromtimestamp(data['citation_date']),\n",
    "                        1, # there is one tweet at a time..\n",
    "                        data['metrics']['citations']['total'], #retweets\n",
    "                        data['author']['followers'], #followers\n",
    "                         ]\n",
    "            csv_writer.writerow(response)\n",
    "      \n",
    "    \n",
    "filename = 'ECE219_tweet_data/tweets_#sb49.txt'\n",
    "output_filename = 'Q1_2#sb49.lol'\n",
    "\n",
    "with open(filename, 'r') as reader:\n",
    "    headers = ['citation_date','tweets','retweets','followers']\n",
    "    with open(output_filename, 'w') as writer:\n",
    "        csv_writer = csv.writer(writer, lineterminator='\\n')\n",
    "        csv_writer.writerow(headers)\n",
    "        for line in reader:\n",
    "            data = json.loads(line)\n",
    "            response = [datetime.datetime.fromtimestamp(data['citation_date']),\n",
    "                        1, # there is one tweet at a time..\n",
    "                        data['metrics']['citations']['total'], #retweets\n",
    "                        data['author']['followers'], #followers\n",
    "                         ]\n",
    "            csv_writer.writerow(response)\n",
    "            \n",
    "filename = 'ECE219_tweet_data/tweets_#superbowl.txt'\n",
    "output_filename = 'Q1_2#superbowl.lol'\n",
    "\n",
    "with open(filename, 'r') as reader:\n",
    "    headers = ['citation_date','tweets','retweets','followers']\n",
    "    with open(output_filename, 'w') as writer:\n",
    "        csv_writer = csv.writer(writer, lineterminator='\\n')\n",
    "        csv_writer.writerow(headers)\n",
    "        for line in reader:\n",
    "            data = json.loads(line)\n",
    "            response = [datetime.datetime.fromtimestamp(data['citation_date']),\n",
    "                        1, # there is one tweet at a time..\n",
    "                        data['metrics']['citations']['total'], #retweets\n",
    "                        data['author']['followers'], #followers\n",
    "                         ]\n",
    "            csv_writer.writerow(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# QUESTION 1: Report the following statistics for each hashtag:\n",
    "# \u000f Average number of tweets per hour\n",
    "# \u000f Average number of followers of users posting the tweets per tweet (to make it simple, we\n",
    "# average over the number of tweets; if a users posted twice, we count the user and the user's\n",
    "# followers twice as well)\n",
    "# \u000f Average number of retweets per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "gohawks = pd.read_csv('Q1_2#gohawks.lol',delimiter=',', parse_dates=['citation_date'])\n",
    "gopatriots = pd.read_csv('Q1_2#gopatriots.lol',delimiter=',', parse_dates=['citation_date'])\n",
    "nfl = pd.read_csv('Q1_2#nfl.lol',delimiter=',', parse_dates=['citation_date'])\n",
    "patriots = pd.read_csv('Q1_2#patriots.lol',delimiter=',', parse_dates=['citation_date'])\n",
    "sb49 = pd.read_csv('Q1_2#sb49.lol',delimiter=',', parse_dates=['citation_date'])\n",
    "superbowl = pd.read_csv('Q1_2#superbowl.lol',delimiter=',', parse_dates=['citation_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([gohawks, gopatriots, nfl, patriots, sb49, superbowl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = full_df.max()\n",
    "min = full_df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (max['citation_date'] - min['citation_date']).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2081588.0000000002"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION 2: Plot \\number of tweets in hour\" over time for #SuperBowl and #NFL (a histogram\n",
    "# with 1-hour bins). The tweets are stored in separate \f",
    "les for different hashtags and \f",
    "les are named\n",
    "# as tweet [#hashtag].txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
